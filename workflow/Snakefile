from os.path import join
import sys
import os
import pandas as pd
import yaml
from snakemake.utils import validate


def get_file_size(filename):
	filename=filename.strip()
	if check_readaccess(filename):
		return os.stat(filename).st_size

def get_fastqs(wildcards):
	d=dict()
	d["R1"]=SAMPLESDF["R1"][wildcards.sample]
	d["R2"]=SAMPLESDF["R2"][wildcards.sample]
	return d

def get_raw_and_trim_fastqs(wildcards):
	d=dict()
	d["R1"]=SAMPLESDF["R1"][wildcards.sample]
	d["R2"]=SAMPLESDF["R2"][wildcards.sample]
	d["R1trim"]=join(WORKDIR,"results",wildcards.sample,"trim",wildcards.sample+".R1.trim.fastq.gz")
	d["R2trim"]=join(WORKDIR,"results",wildcards.sample,"trim",wildcards.sample+".R2.trim.fastq.gz")	
	return d

def get_peorse(wildcards):
	return SAMPLESDF["PEorSE"][wildcards.sample]

def check_existence(filename):
	"""Checks if file exists on filesystem
	:param filename <str>: Name of file to check
	"""
	filename=filename.strip()
	if not os.path.exists(filename):
		sys.exit("File: {} does not exists!".format(filename))
	return True


def check_readaccess(filename):
	"""Checks permissions to see if user can read a file
	:param filename <str>: Name of file to check
	"""
	filename=filename.strip()
	check_existence(filename)
	if not os.access(filename,os.R_OK):
		sys.exit("File: {} exists, but user cannot read from file due to permissions!".format(filename))
	return True


def check_writeaccess(filename):
	"""Checks permissions to see if user can write to a file
	:param filename <str>: Name of file to check
	"""
	filename=filename.strip()
	check_existence(filename)
	if not os.access(filename,os.W_OK):
		sys.exit("File: {} exists, but user cannot write to file due to permissions!".format(filename))
	return True

##### load config and sample sheets #####

check_readaccess("config/config.yaml")
configfile: "config/config.yaml"
#validate(config, "config.schema.yaml")

## set memory limit 
## used for sambamba sort, etc
MEMORYG="100G"

#resouce absolute path
WORKDIR=config['workdir']
SCRIPTS_DIR=config['scriptsdir']
RESOURCES_DIR=config['resourcesdir']
if not os.path.exists(join(WORKDIR,"fastqs")):
	os.mkdir(join(WORKDIR,"fastqs"))
if not os.path.exists(join(WORKDIR,"results")):
	os.mkdir(join(WORKDIR,"results"))
for f in ["samples", "tools", "cluster"]:
	check_readaccess(config[f])

SAMPLESDF = pd.read_csv(config["samples"],sep="\t",header=0,index_col="sampleName")
SAMPLES = list(SAMPLESDF.index)
SAMPLESDF["R1"]=join(RESOURCES_DIR,"dummy")
SAMPLESDF["R2"]=join(RESOURCES_DIR,"dummy")
SAMPLESDF["PEorSE"]="PE"

for sample in SAMPLES:
	R1file=SAMPLESDF["path_to_R1_fastq"][sample]
	R2file=SAMPLESDF["path_to_R2_fastq"][sample]
	# print(sample,R1file,R2file)
	check_readaccess(R1file)
	R1filenewname=join(WORKDIR,"fastqs",sample+".R1.fastq.gz")
	if not os.path.exists(R1filenewname):
		os.symlink(R1file,R1filenewname)
		# os.link(R1file,R1filenewname)
	SAMPLESDF.loc[[sample],"R1"]=R1filenewname
	if str(R2file)!='nan':
		check_readaccess(R2file)
		R2filenewname=join(WORKDIR,"fastqs",sample+".R2.fastq.gz")
		if not os.path.exists(R2filenewname):
			os.symlink(R2file,R2filenewname)
			# os.link(R2file,R2filenewname)
		SAMPLESDF.loc[[sample],"R2"]=R2filenewname
	else:
		SAMPLESDF.loc[[sample],"PEorSE"]="SE"
# print(SAMPLESDF)
# sys.exit()

## Load tools from YAML file
with open(config["tools"]) as f:
	TOOLS = yaml.safe_load(f)


rule all:
	input:
		## cutadapt
		# cutadapt files are now temp() to save space
		expand(join(WORKDIR,"results","{sample}","trim","{sample}.R1.trim.fastq.gz"),sample=SAMPLES),
		expand(join(WORKDIR,"results","{sample}","trim","{sample}.R2.trim.fastq.gz"),sample=SAMPLES),
		## star1p
		#expand(join(WORKDIR,"results","{sample}","STAR1p","{sample}_p1.Chimeric.out.junction"),sample=SAMPLES)
		expand(join(WORKDIR,"results","{sample}","STAR1p","{sample}_p1.Aligned.sortedByCoord.out.bam"),sample=SAMPLES)

rule cutadapt:
	input:
		unpack(get_fastqs)
	output:
		of1=join(WORKDIR,"results","{sample}","trim","{sample}.R1.trim.fastq.gz"),
		of2=join(WORKDIR,"results","{sample}","trim","{sample}.R2.trim.fastq.gz")
	params:
		sample="{sample}",
		workdir=WORKDIR,
		outdir=join(WORKDIR,"results","{sample}"),
		peorse=get_peorse,
		cutadapt_min_length=config["cutadapt_min_length"],
		adapters=join(RESOURCES_DIR,"TruSeq_and_nextera_adapters.consolidated.fa")
	envmodules: TOOLS["cutadapt"]["version"]
	threads: 56
	shell:"""
if [ ! -d {params.outdir} ];then mkdir {params.outdir};fi
if [ "{params.peorse}" == "PE" ];then
	## Paired-end
	cutadapt --pair-filter=any \
	--nextseq-trim=2 \
	--trim-n \
	-n 5 -O 5 \
	-q 10,10 -m {params.cutadapt_min_length}:{params.cutadapt_min_length} \
	-b file:{params.adapters} \
	-B file:{params.adapters} \
	-j {threads} \
	-o {output.of1} -p {output.of2} \
	{input.R1} {input.R2}
else
	## Single-end
	cutadapt \
	--nextseq-trim=2 \
	--trim-n \
	-n 5 -O 5 \
	-q 10,10 -m {params.cutadapt_min_length} \
	-b file:{params.adapters} \
	-j {threads} \
	-o {output.of1} \
	{input.R1}
	touch {output.of2}
fi
"""

rule star1p:
	input:
		R1=rules.cutadapt.output.of1,
		R2=rules.cutadapt.output.of2
	output:
		#junction=join(WORKDIR,"results","{sample}","STAR1p","{sample}_p1.Chimeric.out.junction")
		bam=join(WORKDIR,"results","{sample}","STAR1p","{sample}_p1.Aligned.sortedByCoord.out.bam")
	params:
		sample="{sample}",
		peorse=get_peorse,
		workdir=WORKDIR,
		outdir=join(WORKDIR,"results","{sample}","STAR1p"),
		starindexdir=config['star_index_dir'],
		alignTranscriptsPerReadNmax=TOOLS["star"]["alignTranscriptsPerReadNmax"],
		gtf=config['ref_gtf']
	envmodules: TOOLS["star"]["version"]
	threads: 56
	shell:"""
if [ -d /dev/shm/{params.sample} ];then rm -rf /dev/shm/{params.sample};fi
if [ ! -d {params.outdir} ];then mkdir {params.outdir};fi
if [ "{params.peorse}" == "PE" ];then
# paired-end
	overhang=$(zcat {input} | awk -v maxlen=100 'NR%4==2 {{if (length($1) > maxlen+0) maxlen=length($1)}}; END {{print maxlen-1}}')
	echo "sjdbOverhang for STAR: ${{overhang}}"
	cd {params.outdir}
	STAR --genomeDir {params.starindexdir} \
	--outSAMstrandField None  \
	--outFilterMultimapNmax 20 \
	--alignSJoverhangMin 8 \
	--alignSJDBoverhangMin 1 \
	--outFilterMismatchNmax 999 \
	--outFilterMismatchNoverLmax 0.3  \
	--alignIntronMin 20 \
	--alignIntronMax 1000000 \
	--alignMatesGapMax 1000000 \
	--readFilesIn {input.R1} {input.R2} \
	--readFilesCommand zcat \
	--runThreadN {threads} \
	--outFileNamePrefix {params.sample}_p1. \
	--chimSegmentMin 20 \
	--chimMultimapNmax 10 \
	--chimOutType Junctions \
	--alignTranscriptsPerReadNmax {params.alignTranscriptsPerReadNmax} \
	--outSAMtype BAM SortedByCoordinate \
	--alignEndsProtrude 10 ConcordantPair \
	--outFilterIntronMotifs None \
	--sjdbGTFfile {params.gtf} \
	--outTmpDir=/dev/shm/{params.sample} \
	--sjdbOverhang $overhang

else
#single-end
	overhang=$(zcat {input.R1} | awk -v maxlen=100 'NR%4==2 {{if (length($1) > maxlen+0) maxlen=length($1)}}; END {{print maxlen-1}}')
	echo "sjdbOverhang for STAR: ${{overhang}}"
	cd {params.outdir}
	STAR --genomeDir {params.starindexdir} \
	--outSAMstrandField None  \
	--outFilterMultimapNmax 20 \
	--alignSJoverhangMin 8 \
	--alignSJDBoverhangMin 1 \
	--outFilterMismatchNmax 999 \
	--outFilterMismatchNoverLmax 0.3  \
	--alignIntronMin 20 \
	--alignIntronMax 1000000 \
	--alignMatesGapMax 1000000 \
	--readFilesIn {input.R1} \
	--readFilesCommand zcat \
	--runThreadN {threads} \
	--outFileNamePrefix {params.sample}_p1. \
	--chimSegmentMin 20 \
	--chimMultimapNmax 10 \
	--chimOutType WithinBAM \
	--alignTranscriptsPerReadNmax {params.alignTranscriptsPerReadNmax} \
	--outSAMtype BAM SortedByCoordinate \
	--alignEndsProtrude 10 ConcordantPair \
	--outFilterIntronMotifs None \
	--sjdbGTFfile {params.gtf} \
	--outTmpDir=/dev/shm/{params.sample} \
	--sjdbOverhang $overhang
fi
#rm -rf {params.outdir}/{params.sample}_p1._STARgenome
# rm -rf {params.outdir}/{params.sample}_p1.Aligned.out.bam
"""
